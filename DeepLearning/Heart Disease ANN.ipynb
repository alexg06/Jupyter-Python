{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>cholesteral</th>\n",
       "      <th>thalac</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>disease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>261</td>\n",
       "      <td>141</td>\n",
       "      <td>3</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>263</td>\n",
       "      <td>105</td>\n",
       "      <td>2</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>269</td>\n",
       "      <td>121</td>\n",
       "      <td>2</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sample  cholesteral  thalac  oldpeak   disease\n",
       "0  train          261     141        3  positive\n",
       "1  train          263     105        2  negative\n",
       "2  train          269     121        2  negative"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('heart_disease_for_curves.xls')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>cholesteral</th>\n",
       "      <th>thalac</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train</td>\n",
       "      <td>261</td>\n",
       "      <td>141</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train</td>\n",
       "      <td>263</td>\n",
       "      <td>105</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train</td>\n",
       "      <td>269</td>\n",
       "      <td>121</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sample  cholesteral  thalac  oldpeak  label\n",
       "0  train          261     141        3      1\n",
       "1  train          263     105        2      0\n",
       "2  train          269     121        2      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(df, columns=['disease'], drop_first=True)\n",
    "df.rename(columns={'disease_positive':'label'}, inplace=True)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = df[0:150]\n",
    "df_test = df[150:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>cholesteral</th>\n",
       "      <th>thalac</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>train</td>\n",
       "      <td>308</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>train</td>\n",
       "      <td>193</td>\n",
       "      <td>162</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>train</td>\n",
       "      <td>228</td>\n",
       "      <td>165</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sample  cholesteral  thalac  oldpeak  label\n",
       "147  train          308     170        0      0\n",
       "148  train          193     162       19      0\n",
       "149  train          228     165       10      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>cholesteral</th>\n",
       "      <th>thalac</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>test</td>\n",
       "      <td>231</td>\n",
       "      <td>182</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>test</td>\n",
       "      <td>262</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>test</td>\n",
       "      <td>259</td>\n",
       "      <td>130</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sample  cholesteral  thalac  oldpeak  label\n",
       "150   test          231     182       38      1\n",
       "151   test          262     155        0      0\n",
       "152   test          259     130       30      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_train = df_training['label']\n",
    "label_test = df_test['label']\n",
    "df_training = df_training.drop(['sample', 'label'], axis=1)\n",
    "df_test = df_test.drop(['sample', 'label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cholesteral</th>\n",
       "      <th>thalac</th>\n",
       "      <th>oldpeak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>231</td>\n",
       "      <td>182</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>262</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>259</td>\n",
       "      <td>130</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cholesteral  thalac  oldpeak\n",
       "150          231     182       38\n",
       "151          262     155        0\n",
       "152          259     130       30"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alex\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(3, activation='relu', input_dim=3))\n",
    "model.add(Dense(64, activation='relu')) #best 64 so far\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105 samples, validate on 45 samples\n",
      "Epoch 1/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7142 - acc: 0.6952 - val_loss: 0.6334 - val_acc: 0.6667\n",
      "Epoch 2/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6838 - acc: 0.6667 - val_loss: 0.6006 - val_acc: 0.6000\n",
      "Epoch 3/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6850 - acc: 0.6667 - val_loss: 0.6155 - val_acc: 0.6444\n",
      "Epoch 4/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6850 - acc: 0.6667 - val_loss: 0.5961 - val_acc: 0.6222\n",
      "Epoch 5/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6643 - acc: 0.6381 - val_loss: 0.6028 - val_acc: 0.6444\n",
      "Epoch 6/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6562 - acc: 0.6857 - val_loss: 0.6032 - val_acc: 0.6000\n",
      "Epoch 7/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6632 - acc: 0.6667 - val_loss: 0.5981 - val_acc: 0.6000\n",
      "Epoch 8/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6590 - acc: 0.6571 - val_loss: 0.5983 - val_acc: 0.6000\n",
      "Epoch 9/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6343 - acc: 0.6381 - val_loss: 0.6058 - val_acc: 0.6222\n",
      "Epoch 10/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.7016 - acc: 0.6667 - val_loss: 0.6017 - val_acc: 0.6444\n",
      "Epoch 11/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6728 - acc: 0.6667 - val_loss: 0.5979 - val_acc: 0.6000\n",
      "Epoch 12/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6513 - acc: 0.6667 - val_loss: 0.5938 - val_acc: 0.6000\n",
      "Epoch 13/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6609 - acc: 0.6571 - val_loss: 0.6033 - val_acc: 0.6444\n",
      "Epoch 14/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6825 - acc: 0.6667 - val_loss: 0.5946 - val_acc: 0.6000\n",
      "Epoch 15/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6591 - acc: 0.6857 - val_loss: 0.6037 - val_acc: 0.6000\n",
      "Epoch 16/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6817 - acc: 0.6762 - val_loss: 0.6133 - val_acc: 0.6222\n",
      "Epoch 17/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6745 - acc: 0.6571 - val_loss: 0.6002 - val_acc: 0.6222\n",
      "Epoch 18/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6605 - acc: 0.6476 - val_loss: 0.5981 - val_acc: 0.6222\n",
      "Epoch 19/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6665 - acc: 0.6571 - val_loss: 0.5991 - val_acc: 0.6222\n",
      "Epoch 20/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6485 - acc: 0.6667 - val_loss: 0.5966 - val_acc: 0.6222\n",
      "Epoch 21/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6729 - acc: 0.6571 - val_loss: 0.5976 - val_acc: 0.6000\n",
      "Epoch 22/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6544 - acc: 0.6667 - val_loss: 0.5962 - val_acc: 0.6000\n",
      "Epoch 23/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6590 - acc: 0.6571 - val_loss: 0.6007 - val_acc: 0.6444\n",
      "Epoch 24/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6637 - acc: 0.6667 - val_loss: 0.5954 - val_acc: 0.5778\n",
      "Epoch 25/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6380 - acc: 0.6381 - val_loss: 0.5999 - val_acc: 0.6444\n",
      "Epoch 26/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.7010 - acc: 0.6667 - val_loss: 0.5915 - val_acc: 0.6000\n",
      "Epoch 27/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6734 - acc: 0.6667 - val_loss: 0.5973 - val_acc: 0.6000\n",
      "Epoch 28/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6379 - acc: 0.6762 - val_loss: 0.5966 - val_acc: 0.6222\n",
      "Epoch 29/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6798 - acc: 0.6667 - val_loss: 0.5984 - val_acc: 0.6222\n",
      "Epoch 30/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6664 - acc: 0.6571 - val_loss: 0.5950 - val_acc: 0.6000\n",
      "Epoch 31/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6547 - acc: 0.6667 - val_loss: 0.5972 - val_acc: 0.6222\n",
      "Epoch 32/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6547 - acc: 0.6667 - val_loss: 0.6186 - val_acc: 0.6667\n",
      "Epoch 33/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6791 - acc: 0.6857 - val_loss: 0.5990 - val_acc: 0.6667\n",
      "Epoch 34/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6490 - acc: 0.6667 - val_loss: 0.5952 - val_acc: 0.6667\n",
      "Epoch 35/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6505 - acc: 0.6762 - val_loss: 0.6003 - val_acc: 0.6667\n",
      "Epoch 36/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6439 - acc: 0.6762 - val_loss: 0.5903 - val_acc: 0.6667\n",
      "Epoch 37/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6533 - acc: 0.6476 - val_loss: 0.5927 - val_acc: 0.6444\n",
      "Epoch 38/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6438 - acc: 0.6952 - val_loss: 0.6016 - val_acc: 0.6444\n",
      "Epoch 39/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6768 - acc: 0.6476 - val_loss: 0.6068 - val_acc: 0.5778\n",
      "Epoch 40/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6541 - acc: 0.6667 - val_loss: 0.6012 - val_acc: 0.6000\n",
      "Epoch 41/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6589 - acc: 0.6762 - val_loss: 0.6001 - val_acc: 0.6000\n",
      "Epoch 42/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6901 - acc: 0.6762 - val_loss: 0.6003 - val_acc: 0.6444\n",
      "Epoch 43/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6610 - acc: 0.6571 - val_loss: 0.5989 - val_acc: 0.6667\n",
      "Epoch 44/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6423 - acc: 0.6571 - val_loss: 0.6033 - val_acc: 0.6667\n",
      "Epoch 45/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6542 - acc: 0.6667 - val_loss: 0.5924 - val_acc: 0.6667\n",
      "Epoch 46/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6357 - acc: 0.6667 - val_loss: 0.5976 - val_acc: 0.6222\n",
      "Epoch 47/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6567 - acc: 0.6762 - val_loss: 0.5975 - val_acc: 0.6222\n",
      "Epoch 48/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6491 - acc: 0.6381 - val_loss: 0.5915 - val_acc: 0.6444\n",
      "Epoch 49/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6490 - acc: 0.6857 - val_loss: 0.5900 - val_acc: 0.6444\n",
      "Epoch 50/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6344 - acc: 0.6667 - val_loss: 0.6131 - val_acc: 0.6667\n",
      "Epoch 51/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6159 - acc: 0.6762 - val_loss: 0.6088 - val_acc: 0.6222\n",
      "Epoch 52/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.5960 - acc: 0.6667 - val_loss: 0.6743 - val_acc: 0.6667\n",
      "Epoch 53/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6644 - acc: 0.6952 - val_loss: 0.5956 - val_acc: 0.6444\n",
      "Epoch 54/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6420 - acc: 0.6762 - val_loss: 0.5986 - val_acc: 0.6222\n",
      "Epoch 55/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6450 - acc: 0.6571 - val_loss: 0.6033 - val_acc: 0.6667\n",
      "Epoch 56/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6220 - acc: 0.6571 - val_loss: 0.6259 - val_acc: 0.6667\n",
      "Epoch 57/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6579 - acc: 0.6857 - val_loss: 0.5959 - val_acc: 0.6667\n",
      "Epoch 58/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6431 - acc: 0.6571 - val_loss: 0.5962 - val_acc: 0.6444\n",
      "Epoch 59/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6395 - acc: 0.6571 - val_loss: 0.5919 - val_acc: 0.6667\n",
      "Epoch 60/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6446 - acc: 0.6857 - val_loss: 0.6011 - val_acc: 0.6667\n",
      "Epoch 61/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6384 - acc: 0.6762 - val_loss: 0.5994 - val_acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6336 - acc: 0.6762 - val_loss: 0.6002 - val_acc: 0.6667\n",
      "Epoch 63/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6382 - acc: 0.6571 - val_loss: 0.5912 - val_acc: 0.6667\n",
      "Epoch 64/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6234 - acc: 0.6762 - val_loss: 0.6337 - val_acc: 0.6444\n",
      "Epoch 65/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6490 - acc: 0.6571 - val_loss: 0.6058 - val_acc: 0.6667\n",
      "Epoch 66/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6389 - acc: 0.6667 - val_loss: 0.5988 - val_acc: 0.6444\n",
      "Epoch 67/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6473 - acc: 0.6667 - val_loss: 0.5938 - val_acc: 0.6444\n",
      "Epoch 68/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6356 - acc: 0.6762 - val_loss: 0.5955 - val_acc: 0.6667\n",
      "Epoch 69/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.5925 - acc: 0.6762 - val_loss: 0.6387 - val_acc: 0.6667\n",
      "Epoch 70/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6332 - acc: 0.6762 - val_loss: 0.6045 - val_acc: 0.6667\n",
      "Epoch 71/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6501 - acc: 0.7238 - val_loss: 0.5998 - val_acc: 0.6667\n",
      "Epoch 72/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6549 - acc: 0.6762 - val_loss: 0.5966 - val_acc: 0.6667\n",
      "Epoch 73/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6392 - acc: 0.6857 - val_loss: 0.6042 - val_acc: 0.6444\n",
      "Epoch 74/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6410 - acc: 0.6762 - val_loss: 0.5927 - val_acc: 0.6667\n",
      "Epoch 75/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6401 - acc: 0.6667 - val_loss: 0.5935 - val_acc: 0.6667\n",
      "Epoch 76/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6316 - acc: 0.6667 - val_loss: 0.6111 - val_acc: 0.6667\n",
      "Epoch 77/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6776 - acc: 0.6857 - val_loss: 0.5933 - val_acc: 0.6667\n",
      "Epoch 78/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6349 - acc: 0.6762 - val_loss: 0.5936 - val_acc: 0.6667\n",
      "Epoch 79/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6347 - acc: 0.6762 - val_loss: 0.5944 - val_acc: 0.6667\n",
      "Epoch 80/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6445 - acc: 0.6762 - val_loss: 0.5937 - val_acc: 0.6444\n",
      "Epoch 81/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6293 - acc: 0.6667 - val_loss: 0.5932 - val_acc: 0.6667\n",
      "Epoch 82/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6395 - acc: 0.6571 - val_loss: 0.5902 - val_acc: 0.6444\n",
      "Epoch 83/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6178 - acc: 0.6667 - val_loss: 0.6147 - val_acc: 0.6667\n",
      "Epoch 84/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6394 - acc: 0.6857 - val_loss: 0.5904 - val_acc: 0.6444\n",
      "Epoch 85/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6037 - acc: 0.6857 - val_loss: 0.6263 - val_acc: 0.6667\n",
      "Epoch 86/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6517 - acc: 0.7048 - val_loss: 0.6050 - val_acc: 0.6667\n",
      "Epoch 87/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6755 - acc: 0.6857 - val_loss: 0.5969 - val_acc: 0.6667\n",
      "Epoch 88/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6475 - acc: 0.6571 - val_loss: 0.5968 - val_acc: 0.6667\n",
      "Epoch 89/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6475 - acc: 0.6857 - val_loss: 0.6322 - val_acc: 0.6667\n",
      "Epoch 90/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6559 - acc: 0.6762 - val_loss: 0.6003 - val_acc: 0.6667\n",
      "Epoch 91/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6362 - acc: 0.6762 - val_loss: 0.5991 - val_acc: 0.6444\n",
      "Epoch 92/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6579 - acc: 0.6667 - val_loss: 0.5929 - val_acc: 0.6667\n",
      "Epoch 93/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6422 - acc: 0.6762 - val_loss: 0.5959 - val_acc: 0.6444\n",
      "Epoch 94/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6438 - acc: 0.6762 - val_loss: 0.5935 - val_acc: 0.6667\n",
      "Epoch 95/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6531 - acc: 0.6762 - val_loss: 0.5909 - val_acc: 0.6667\n",
      "Epoch 96/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6447 - acc: 0.6857 - val_loss: 0.5928 - val_acc: 0.6889\n",
      "Epoch 97/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6453 - acc: 0.6762 - val_loss: 0.5907 - val_acc: 0.6444\n",
      "Epoch 98/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6253 - acc: 0.6667 - val_loss: 0.6039 - val_acc: 0.6667\n",
      "Epoch 99/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6482 - acc: 0.6667 - val_loss: 0.5919 - val_acc: 0.6667\n",
      "Epoch 100/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6284 - acc: 0.6762 - val_loss: 0.6066 - val_acc: 0.6000\n",
      "Epoch 101/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6570 - acc: 0.6762 - val_loss: 0.5935 - val_acc: 0.6667\n",
      "Epoch 102/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6190 - acc: 0.6857 - val_loss: 0.6505 - val_acc: 0.6667\n",
      "Epoch 103/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6888 - acc: 0.6762 - val_loss: 0.6039 - val_acc: 0.6000\n",
      "Epoch 104/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6664 - acc: 0.6762 - val_loss: 0.6013 - val_acc: 0.6667\n",
      "Epoch 105/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6868 - acc: 0.6667 - val_loss: 0.6057 - val_acc: 0.6444\n",
      "Epoch 106/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6797 - acc: 0.6857 - val_loss: 0.6004 - val_acc: 0.6000\n",
      "Epoch 107/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6525 - acc: 0.6762 - val_loss: 0.5950 - val_acc: 0.6667\n",
      "Epoch 108/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6479 - acc: 0.6667 - val_loss: 0.5990 - val_acc: 0.6000\n",
      "Epoch 109/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6509 - acc: 0.6667 - val_loss: 0.6054 - val_acc: 0.6000\n",
      "Epoch 110/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6532 - acc: 0.6762 - val_loss: 0.5956 - val_acc: 0.6667\n",
      "Epoch 111/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6320 - acc: 0.6667 - val_loss: 0.5920 - val_acc: 0.6667\n",
      "Epoch 112/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6561 - acc: 0.6667 - val_loss: 0.5900 - val_acc: 0.6667\n",
      "Epoch 113/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6354 - acc: 0.6952 - val_loss: 0.5888 - val_acc: 0.6667\n",
      "Epoch 114/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6387 - acc: 0.6952 - val_loss: 0.5934 - val_acc: 0.6444\n",
      "Epoch 115/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6411 - acc: 0.6571 - val_loss: 0.5899 - val_acc: 0.6667\n",
      "Epoch 116/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6223 - acc: 0.6571 - val_loss: 0.6064 - val_acc: 0.6444\n",
      "Epoch 117/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6532 - acc: 0.6667 - val_loss: 0.5921 - val_acc: 0.6667\n",
      "Epoch 118/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6556 - acc: 0.6667 - val_loss: 0.5950 - val_acc: 0.6667\n",
      "Epoch 119/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6429 - acc: 0.6667 - val_loss: 0.6030 - val_acc: 0.6667\n",
      "Epoch 120/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6263 - acc: 0.6667 - val_loss: 0.5923 - val_acc: 0.6667\n",
      "Epoch 121/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6486 - acc: 0.6762 - val_loss: 0.5903 - val_acc: 0.6667\n",
      "Epoch 122/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6326 - acc: 0.6667 - val_loss: 0.5920 - val_acc: 0.6889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6347 - acc: 0.6571 - val_loss: 0.5909 - val_acc: 0.6444\n",
      "Epoch 124/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6367 - acc: 0.6667 - val_loss: 0.5907 - val_acc: 0.6444\n",
      "Epoch 125/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6326 - acc: 0.6667 - val_loss: 0.6004 - val_acc: 0.6667\n",
      "Epoch 126/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6336 - acc: 0.6667 - val_loss: 0.5949 - val_acc: 0.6667\n",
      "Epoch 127/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6410 - acc: 0.6762 - val_loss: 0.5919 - val_acc: 0.6444\n",
      "Epoch 128/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6296 - acc: 0.6952 - val_loss: 0.5969 - val_acc: 0.6667\n",
      "Epoch 129/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6372 - acc: 0.6667 - val_loss: 0.5914 - val_acc: 0.6667\n",
      "Epoch 130/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6312 - acc: 0.6952 - val_loss: 0.5911 - val_acc: 0.6667\n",
      "Epoch 131/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6320 - acc: 0.6762 - val_loss: 0.6043 - val_acc: 0.6667\n",
      "Epoch 132/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6286 - acc: 0.6571 - val_loss: 0.5891 - val_acc: 0.6444\n",
      "Epoch 133/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6351 - acc: 0.6667 - val_loss: 0.5900 - val_acc: 0.6667\n",
      "Epoch 134/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6283 - acc: 0.6762 - val_loss: 0.5886 - val_acc: 0.6444\n",
      "Epoch 135/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6367 - acc: 0.6571 - val_loss: 0.5881 - val_acc: 0.6444\n",
      "Epoch 136/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6222 - acc: 0.6952 - val_loss: 0.6062 - val_acc: 0.6667\n",
      "Epoch 137/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6427 - acc: 0.6762 - val_loss: 0.5895 - val_acc: 0.6667\n",
      "Epoch 138/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6531 - acc: 0.6762 - val_loss: 0.6062 - val_acc: 0.6000\n",
      "Epoch 139/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6270 - acc: 0.6667 - val_loss: 0.6066 - val_acc: 0.6667\n",
      "Epoch 140/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6605 - acc: 0.6667 - val_loss: 0.5976 - val_acc: 0.6667\n",
      "Epoch 141/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6232 - acc: 0.7048 - val_loss: 0.6446 - val_acc: 0.6667\n",
      "Epoch 142/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6610 - acc: 0.6381 - val_loss: 0.5929 - val_acc: 0.6889\n",
      "Epoch 143/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6405 - acc: 0.6762 - val_loss: 0.5891 - val_acc: 0.6667\n",
      "Epoch 144/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6322 - acc: 0.7048 - val_loss: 0.5897 - val_acc: 0.6667\n",
      "Epoch 145/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6332 - acc: 0.6762 - val_loss: 0.5896 - val_acc: 0.6667\n",
      "Epoch 146/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6338 - acc: 0.6762 - val_loss: 0.5889 - val_acc: 0.6667\n",
      "Epoch 147/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6250 - acc: 0.6762 - val_loss: 0.5975 - val_acc: 0.6667\n",
      "Epoch 148/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6302 - acc: 0.6667 - val_loss: 0.5952 - val_acc: 0.6889\n",
      "Epoch 149/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6278 - acc: 0.6857 - val_loss: 0.5943 - val_acc: 0.6667\n",
      "Epoch 150/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6342 - acc: 0.6667 - val_loss: 0.5956 - val_acc: 0.6889\n",
      "Epoch 151/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6281 - acc: 0.6667 - val_loss: 0.5964 - val_acc: 0.6667\n",
      "Epoch 152/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6410 - acc: 0.6667 - val_loss: 0.5966 - val_acc: 0.6667\n",
      "Epoch 153/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6433 - acc: 0.6762 - val_loss: 0.5942 - val_acc: 0.6889\n",
      "Epoch 154/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6392 - acc: 0.6952 - val_loss: 0.5955 - val_acc: 0.6667\n",
      "Epoch 155/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6376 - acc: 0.6571 - val_loss: 0.5925 - val_acc: 0.6889\n",
      "Epoch 156/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6507 - acc: 0.6667 - val_loss: 0.5918 - val_acc: 0.6889\n",
      "Epoch 157/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6324 - acc: 0.7048 - val_loss: 0.5992 - val_acc: 0.6667\n",
      "Epoch 158/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6645 - acc: 0.6571 - val_loss: 0.5965 - val_acc: 0.6444\n",
      "Epoch 159/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6465 - acc: 0.6762 - val_loss: 0.5961 - val_acc: 0.6444\n",
      "Epoch 160/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6432 - acc: 0.6952 - val_loss: 0.5962 - val_acc: 0.6667\n",
      "Epoch 161/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6514 - acc: 0.6762 - val_loss: 0.5986 - val_acc: 0.6667\n",
      "Epoch 162/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6557 - acc: 0.6762 - val_loss: 0.5931 - val_acc: 0.6889\n",
      "Epoch 163/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6354 - acc: 0.6857 - val_loss: 0.5913 - val_acc: 0.6667\n",
      "Epoch 164/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6347 - acc: 0.6762 - val_loss: 0.5896 - val_acc: 0.6444\n",
      "Epoch 165/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6274 - acc: 0.6667 - val_loss: 0.5900 - val_acc: 0.6444\n",
      "Epoch 166/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6428 - acc: 0.6762 - val_loss: 0.5913 - val_acc: 0.6667\n",
      "Epoch 167/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6329 - acc: 0.6571 - val_loss: 0.5897 - val_acc: 0.6444\n",
      "Epoch 168/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6629 - acc: 0.6762 - val_loss: 0.5922 - val_acc: 0.6889\n",
      "Epoch 169/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6332 - acc: 0.6667 - val_loss: 0.5903 - val_acc: 0.6667\n",
      "Epoch 170/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6254 - acc: 0.6571 - val_loss: 0.5918 - val_acc: 0.6667\n",
      "Epoch 171/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6378 - acc: 0.6952 - val_loss: 0.6056 - val_acc: 0.6667\n",
      "Epoch 172/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6459 - acc: 0.7048 - val_loss: 0.5950 - val_acc: 0.6667\n",
      "Epoch 173/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6319 - acc: 0.6762 - val_loss: 0.6045 - val_acc: 0.6667\n",
      "Epoch 174/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6445 - acc: 0.6857 - val_loss: 0.5984 - val_acc: 0.6667\n",
      "Epoch 175/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6425 - acc: 0.6762 - val_loss: 0.5915 - val_acc: 0.6889\n",
      "Epoch 176/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6295 - acc: 0.6667 - val_loss: 0.5898 - val_acc: 0.6667\n",
      "Epoch 177/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6384 - acc: 0.6857 - val_loss: 0.6088 - val_acc: 0.6222\n",
      "Epoch 178/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6383 - acc: 0.6667 - val_loss: 0.5959 - val_acc: 0.6889\n",
      "Epoch 179/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6390 - acc: 0.6857 - val_loss: 0.6043 - val_acc: 0.6222\n",
      "Epoch 180/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6309 - acc: 0.6762 - val_loss: 0.6002 - val_acc: 0.6667\n",
      "Epoch 181/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6361 - acc: 0.6762 - val_loss: 0.5905 - val_acc: 0.6444\n",
      "Epoch 182/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6377 - acc: 0.6762 - val_loss: 0.5962 - val_acc: 0.6444\n",
      "Epoch 183/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6458 - acc: 0.6857 - val_loss: 0.5920 - val_acc: 0.6889\n",
      "Epoch 184/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6329 - acc: 0.6857 - val_loss: 0.5914 - val_acc: 0.6667\n",
      "Epoch 185/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6384 - acc: 0.6952 - val_loss: 0.5926 - val_acc: 0.6889\n",
      "Epoch 186/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6374 - acc: 0.6762 - val_loss: 0.6018 - val_acc: 0.6222\n",
      "Epoch 187/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6323 - acc: 0.6762 - val_loss: 0.5915 - val_acc: 0.6889\n",
      "Epoch 188/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6180 - acc: 0.6857 - val_loss: 0.6019 - val_acc: 0.7111\n",
      "Epoch 189/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6327 - acc: 0.6857 - val_loss: 0.5906 - val_acc: 0.6889\n",
      "Epoch 190/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6360 - acc: 0.7048 - val_loss: 0.5862 - val_acc: 0.6667\n",
      "Epoch 191/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6212 - acc: 0.6857 - val_loss: 0.6031 - val_acc: 0.7333\n",
      "Epoch 192/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6297 - acc: 0.6952 - val_loss: 0.6039 - val_acc: 0.6889\n",
      "Epoch 193/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6285 - acc: 0.6667 - val_loss: 0.5933 - val_acc: 0.6889\n",
      "Epoch 194/200\n",
      "105/105 [==============================] - 0s 2ms/step - loss: 0.6200 - acc: 0.6571 - val_loss: 0.6110 - val_acc: 0.6667\n",
      "Epoch 195/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6397 - acc: 0.6762 - val_loss: 0.5847 - val_acc: 0.6667\n",
      "Epoch 196/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6341 - acc: 0.6571 - val_loss: 0.6023 - val_acc: 0.6889\n",
      "Epoch 197/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6298 - acc: 0.6762 - val_loss: 0.5966 - val_acc: 0.6889\n",
      "Epoch 198/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6217 - acc: 0.6762 - val_loss: 0.5921 - val_acc: 0.6667\n",
      "Epoch 199/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6315 - acc: 0.6857 - val_loss: 0.5894 - val_acc: 0.6667\n",
      "Epoch 200/200\n",
      "105/105 [==============================] - 0s 3ms/step - loss: 0.6106 - acc: 0.6762 - val_loss: 0.6137 - val_acc: 0.7111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b545a9c278>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(df_training,label_train, epochs=200, verbose=1, validation_split=0.3, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21550204],\n",
       "       [0.29848573],\n",
       "       [0.65426075],\n",
       "       [0.04318606],\n",
       "       [0.16906658],\n",
       "       [0.09638383],\n",
       "       [0.16639361],\n",
       "       [0.65426075],\n",
       "       [0.65426075],\n",
       "       [0.65426075],\n",
       "       [0.00795098],\n",
       "       [0.65426075],\n",
       "       [0.65426075],\n",
       "       [0.65426075],\n",
       "       [0.15038107],\n",
       "       [0.02415436],\n",
       "       [0.02348501],\n",
       "       [0.65426075],\n",
       "       [0.01550397],\n",
       "       [0.65426075],\n",
       "       [0.06117427],\n",
       "       [0.65426075],\n",
       "       [0.65426075],\n",
       "       [0.19989176],\n",
       "       [0.65426075],\n",
       "       [0.65426075],\n",
       "       [0.53695583],\n",
       "       [0.65426075],\n",
       "       [0.496833  ],\n",
       "       [0.07115443],\n",
       "       [0.33559507],\n",
       "       [0.65426075],\n",
       "       [0.13923857],\n",
       "       [0.5200917 ],\n",
       "       [0.6035049 ],\n",
       "       [0.65426075],\n",
       "       [0.36818457],\n",
       "       [0.65426075],\n",
       "       [0.63600725],\n",
       "       [0.65426075],\n",
       "       [0.4561845 ],\n",
       "       [0.65426075],\n",
       "       [0.22410621],\n",
       "       [0.65426075],\n",
       "       [0.24318403],\n",
       "       [0.5439891 ],\n",
       "       [0.38723415],\n",
       "       [0.65426075],\n",
       "       [0.04177609],\n",
       "       [0.07740143],\n",
       "       [0.10384617],\n",
       "       [0.03322089],\n",
       "       [0.65426075],\n",
       "       [0.65426075],\n",
       "       [0.01370245],\n",
       "       [0.65426075],\n",
       "       [0.01188251],\n",
       "       [0.18083309],\n",
       "       [0.65426075],\n",
       "       [0.59367937],\n",
       "       [0.00335963],\n",
       "       [0.65426075],\n",
       "       [0.04604674],\n",
       "       [0.1544574 ],\n",
       "       [0.5406334 ],\n",
       "       [0.65426075],\n",
       "       [0.09069089],\n",
       "       [0.63039905],\n",
       "       [0.23524956],\n",
       "       [0.6396736 ],\n",
       "       [0.65426075],\n",
       "       [0.3628842 ],\n",
       "       [0.6368293 ],\n",
       "       [0.65426075],\n",
       "       [0.65426075],\n",
       "       [0.65426075],\n",
       "       [0.22561419],\n",
       "       [0.65551865],\n",
       "       [0.15626554],\n",
       "       [0.65426075],\n",
       "       [0.65112406],\n",
       "       [0.01077291],\n",
       "       [0.627753  ],\n",
       "       [0.19017078],\n",
       "       [0.13906203],\n",
       "       [0.64263844],\n",
       "       [0.6529066 ],\n",
       "       [0.65426075],\n",
       "       [0.65426075],\n",
       "       [0.16215996],\n",
       "       [0.65426075],\n",
       "       [0.65384626],\n",
       "       [0.65426075],\n",
       "       [0.17103387],\n",
       "       [0.08795547],\n",
       "       [0.03803276],\n",
       "       [0.10058374],\n",
       "       [0.65426075],\n",
       "       [0.06622979],\n",
       "       [0.65426075],\n",
       "       [0.65426075],\n",
       "       [0.65426075],\n",
       "       [0.11340836],\n",
       "       [0.65426075],\n",
       "       [0.03669715],\n",
       "       [0.6331653 ],\n",
       "       [0.65426075],\n",
       "       [0.65426075],\n",
       "       [0.10431931],\n",
       "       [0.2064966 ],\n",
       "       [0.41947424],\n",
       "       [0.65426075],\n",
       "       [0.40734082],\n",
       "       [0.52942795],\n",
       "       [0.21626204],\n",
       "       [0.0407587 ],\n",
       "       [0.00282753],\n",
       "       [0.51328444],\n",
       "       [0.65426075],\n",
       "       [0.4018268 ]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = model.predict(df_test)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "y_predict = np.round(y_predict)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Disease  Healthy\n",
      "Disease       42       24\n",
      "Healthy       14       40\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion = confusion_matrix(label_test, y_predict)\n",
    "confusion = pd.DataFrame(confusion, columns=['Disease', 'Healthy'], index=['Disease', 'Healthy'])\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b545df7ba8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "y_pred_keras = model.predict(df_test).ravel()\n",
    "false_prediction, true_prediction, threshold = roc_curve(label_test, y_pred_keras)\n",
    "\n",
    "plt.plot(false_prediction,true_prediction, color='g')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WITH SKLEARN MLP CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score is 0.725\n",
      "         Disease  Healthy\n",
      "Disease       47       19\n",
      "Healthy       14       40\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model_mlp = MLPClassifier(activation='relu', alpha=0.001, solver='lbfgs', validation_fraction=0.1,batch_size=1)\n",
    "mlp = model_mlp.fit(df_training, label_train)\n",
    "y_predict_mlp = mlp.predict(df_test)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "score = mlp.score(df_test, label_test)\n",
    "print('Score is {}'.format(score))\n",
    "confusion_mlp = confusion_matrix(label_test, y_predict_mlp)\n",
    "confusion_mlp = pd.DataFrame(confusion_mlp, columns=['Disease', 'Healthy'], index=['Disease', 'Healthy'])\n",
    "print(confusion_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
